{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network for Self-Driving Car\n",
    "\n",
    "UPDATE - NEW IMAGE SIZES ARE NOW 18X22 (396)\n",
    "\n",
    "Plan of Attack:\n",
    "    - Import all images from training set:\n",
    "        - Forward, Left and Right Folders\n",
    "    - Resize all the images to 72x88\n",
    "    - Convert images to greyscale:\n",
    "        - Placing the new images in a new array\n",
    "    - Now Reshaping to create a new array which contains flattened images (6336)\n",
    "        - Shape now (3000, 6336)\n",
    "    - Add the appropirate labels to each data\n",
    "    - Shuffle the 3 image arrays and the 3 label array corresondingly\n",
    "    - Append all three arrays to a new array:\n",
    "        - One containing all image data\n",
    "        - One containing all labelled data\n",
    "    - Init all TensorFlow variables and constants\n",
    "    - Start an Interative Session\n",
    "    - Start the training:\n",
    "        - Make sure to add saving capabilities\n",
    "    - Once trained and saved - YOU HAVE YOUR MODEL!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf                    #Machine Learning Library\n",
    "import matplotlib.pyplot as plt            #Display the images for verification\n",
    "import numpy as np                         #Mathematical and arrays library\n",
    "from scipy import misc                     #Image Importing module\n",
    "from skimage.transform import resize       #Resizing image module\n",
    "from sklearn.utils import shuffle          #Shuffle in random order module\n",
    "import glob                                #Iterating through all pictures library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greyscale Conversion Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightedAverage(pixel):\n",
    "    return 0.299*pixel[0] + 0.587*pixel[1] + 0.114*pixel[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Array image importing / resizing / convert / reshape / labelling / shuffleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating initial array and resizing\n",
    "f_image_list = []\n",
    "img_count = 0\n",
    "path = 'C:/Users/Hannan Saleemi/Desktop/Self-Driving Car/cardataset/training_set/Forward/'\n",
    "for filename in glob.glob(path+'*.png'):\n",
    "    img_count += 1\n",
    "    image = misc.imread(path+'trainframe ('+str(img_count)+').png')\n",
    "    image_resized = resize(image, (18,22), mode='reflect')\n",
    "    f_image_list.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "#Just confiming the shape of the array\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished converting image # 0\n",
      "Finished converting image # 100\n",
      "Finished converting image # 200\n",
      "Finished converting image # 300\n",
      "Finished converting image # 400\n",
      "Finished converting image # 500\n",
      "Finished converting image # 600\n",
      "Finished converting image # 700\n",
      "Finished converting image # 800\n",
      "Finished converting image # 900\n",
      "Finished converting image # 1000\n",
      "Finished converting image # 1100\n",
      "Finished converting image # 1200\n",
      "Finished converting image # 1300\n",
      "Finished converting image # 1400\n",
      "Finished converting image # 1500\n",
      "Finished converting image # 1600\n",
      "Finished converting image # 1700\n",
      "Finished converting image # 1800\n",
      "Finished converting image # 1900\n",
      "Finished converting image # 2000\n",
      "Finished converting image # 2100\n",
      "Finished converting image # 2200\n",
      "Finished converting image # 2300\n",
      "Finished converting image # 2400\n",
      "Finished converting image # 2500\n",
      "Finished converting image # 2600\n",
      "Finished converting image # 2700\n",
      "Finished converting image # 2800\n",
      "Finished converting image # 2900\n"
     ]
    }
   ],
   "source": [
    "#Converting to greyscale\n",
    "f_grey = np.zeros((3000, image_resized.shape[0], image_resized.shape[1]))\n",
    "\n",
    "for image_num in range(len(f_image_list)):\n",
    "    for rownum in range(len(f_image_list[image_num])):\n",
    "        for colnum in range(len(f_image_list[image_num][rownum])):\n",
    "            f_grey[image_num][rownum][colnum] = weightedAverage(f_image_list[image_num][rownum][colnum])\n",
    "    #Output Logging\n",
    "    if image_num % 100 == 0:\n",
    "        print(\"Finished converting image #\", (image_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 18, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the shape of the greyscale array\n",
    "f_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "f_images = f_grey.reshape(3000,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 396)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the new shape again\n",
    "f_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "f_labels = np.zeros(shape=(3000,3))\n",
    "\n",
    "#Adding 3000 forward labels [1,0,0]\n",
    "for i in range(3000):\n",
    "    f_labels[i][0] = float(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the labels\n",
    "f_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "f_images, f_labels = shuffle(f_images, f_labels, random_state = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20488431,  0.31913235,  0.40438627, ...,  0.93290392,\n",
       "         0.91115392,  0.90059118],\n",
       "       [ 0.16452059,  0.23098333,  0.24517451, ...,  0.45037843,\n",
       "         0.64341667,  0.86788725],\n",
       "       [ 0.52245294,  0.53974706,  0.56372451, ...,  0.88922059,\n",
       "         0.87743824,  0.86189804],\n",
       "       ..., \n",
       "       [ 0.12021863,  0.10482941,  0.12077941, ...,  0.52446667,\n",
       "         0.47657353,  0.7271    ],\n",
       "       [ 0.55091176,  0.57213137,  0.62195784, ...,  0.89393235,\n",
       "         0.88511961,  0.87136176],\n",
       "       [ 0.06414314,  0.05195686,  0.09219804, ...,  0.61300686,\n",
       "         0.5555402 ,  0.49911863]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if they have shuffled\n",
    "f_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Images Done:\n",
    "    - f_images - contain images\n",
    "    - f_lables - contain labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Array image importing / resizing / convert / reshape / labelling / shuffleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating initial array and resizing\n",
    "l_image_list = []\n",
    "img_count = 0\n",
    "path = 'C:/Users/Hannan Saleemi/Desktop/Self-Driving Car/cardataset/training_set/Left/'\n",
    "for filename in glob.glob(path+'*.png'):\n",
    "    img_count += 1\n",
    "    image = misc.imread(path+'trainframe ('+str(img_count)+').png')\n",
    "    image_resized = resize(image, (18,22), mode='reflect')\n",
    "    l_image_list.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "#Just confiming the shape of the array\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished converting image # 0\n",
      "Finished converting image # 100\n",
      "Finished converting image # 200\n",
      "Finished converting image # 300\n",
      "Finished converting image # 400\n",
      "Finished converting image # 500\n",
      "Finished converting image # 600\n",
      "Finished converting image # 700\n",
      "Finished converting image # 800\n",
      "Finished converting image # 900\n",
      "Finished converting image # 1000\n",
      "Finished converting image # 1100\n",
      "Finished converting image # 1200\n",
      "Finished converting image # 1300\n",
      "Finished converting image # 1400\n",
      "Finished converting image # 1500\n",
      "Finished converting image # 1600\n",
      "Finished converting image # 1700\n",
      "Finished converting image # 1800\n",
      "Finished converting image # 1900\n",
      "Finished converting image # 2000\n",
      "Finished converting image # 2100\n",
      "Finished converting image # 2200\n",
      "Finished converting image # 2300\n",
      "Finished converting image # 2400\n",
      "Finished converting image # 2500\n",
      "Finished converting image # 2600\n",
      "Finished converting image # 2700\n",
      "Finished converting image # 2800\n",
      "Finished converting image # 2900\n"
     ]
    }
   ],
   "source": [
    "#Converting to greyscale\n",
    "l_grey = np.zeros((3000, image_resized.shape[0], image_resized.shape[1]))\n",
    "\n",
    "for image_num in range(len(l_image_list)):\n",
    "    for rownum in range(len(l_image_list[image_num])):\n",
    "        for colnum in range(len(l_image_list[image_num][rownum])):\n",
    "            l_grey[image_num][rownum][colnum] = weightedAverage(l_image_list[image_num][rownum][colnum])\n",
    "    #Output Logging\n",
    "    if image_num % 100 == 0:\n",
    "        print(\"Finished converting image #\", (image_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 18, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the shape of the greyscale array\n",
    "l_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "l_images = l_grey.reshape(3000,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 396)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the new shape again\n",
    "l_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "l_labels = np.zeros(shape=(3000,3))\n",
    "\n",
    "#Adding 3000 forward labels [1,0,0]\n",
    "for i in range(3000):\n",
    "    l_labels[i][1] = float(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the labels\n",
    "l_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "l_images, l_labels = shuffle(l_images, l_labels, random_state = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20488431,  0.31913235,  0.40438627, ...,  0.93290392,\n",
       "         0.91115392,  0.90059118],\n",
       "       [ 0.16452059,  0.23098333,  0.24517451, ...,  0.45037843,\n",
       "         0.64341667,  0.86788725],\n",
       "       [ 0.52245294,  0.53974706,  0.56372451, ...,  0.88922059,\n",
       "         0.87743824,  0.86189804],\n",
       "       ..., \n",
       "       [ 0.12021863,  0.10482941,  0.12077941, ...,  0.52446667,\n",
       "         0.47657353,  0.7271    ],\n",
       "       [ 0.55091176,  0.57213137,  0.62195784, ...,  0.89393235,\n",
       "         0.88511961,  0.87136176],\n",
       "       [ 0.06414314,  0.05195686,  0.09219804, ...,  0.61300686,\n",
       "         0.5555402 ,  0.49911863]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if they have shuffled\n",
    "f_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Images Done:\n",
    "    - l_images - contain images\n",
    "    - l_lables - contain labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Array image importing / resizing / convert / reshape / labelling / shuffleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating initial array and resizing\n",
    "r_image_list = []\n",
    "img_count = 0\n",
    "path = 'C:/Users/Hannan Saleemi/Desktop/Self-Driving Car/cardataset/training_set/Right/'\n",
    "for filename in glob.glob(path+'*.png'):\n",
    "    img_count += 1\n",
    "    image = misc.imread(path+'trainframe ('+str(img_count)+').png')\n",
    "    image_resized = resize(image, (18,22), mode='reflect')\n",
    "    r_image_list.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "#Just confiming the shape of the array\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished converting image # 0\n",
      "Finished converting image # 100\n",
      "Finished converting image # 200\n",
      "Finished converting image # 300\n",
      "Finished converting image # 400\n",
      "Finished converting image # 500\n",
      "Finished converting image # 600\n",
      "Finished converting image # 700\n",
      "Finished converting image # 800\n",
      "Finished converting image # 900\n",
      "Finished converting image # 1000\n",
      "Finished converting image # 1100\n",
      "Finished converting image # 1200\n",
      "Finished converting image # 1300\n",
      "Finished converting image # 1400\n",
      "Finished converting image # 1500\n",
      "Finished converting image # 1600\n",
      "Finished converting image # 1700\n",
      "Finished converting image # 1800\n",
      "Finished converting image # 1900\n",
      "Finished converting image # 2000\n",
      "Finished converting image # 2100\n",
      "Finished converting image # 2200\n",
      "Finished converting image # 2300\n",
      "Finished converting image # 2400\n",
      "Finished converting image # 2500\n",
      "Finished converting image # 2600\n",
      "Finished converting image # 2700\n",
      "Finished converting image # 2800\n",
      "Finished converting image # 2900\n"
     ]
    }
   ],
   "source": [
    "#Converting to greyscale\n",
    "r_grey = np.zeros((3000, image_resized.shape[0], image_resized.shape[1]))\n",
    "\n",
    "for image_num in range(len(r_image_list)):\n",
    "    for rownum in range(len(r_image_list[image_num])):\n",
    "        for colnum in range(len(r_image_list[image_num][rownum])):\n",
    "            r_grey[image_num][rownum][colnum] = weightedAverage(r_image_list[image_num][rownum][colnum])\n",
    "    #Output Logging\n",
    "    if image_num % 100 == 0:\n",
    "        print(\"Finished converting image #\", (image_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 18, 22)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the shape of the greyscale array\n",
    "r_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "r_images = r_grey.reshape(3000,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 396)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the new shape again\n",
    "r_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "r_labels = np.zeros(shape=(3000,3))\n",
    "\n",
    "#Adding 3000 forward labels [1,0,0]\n",
    "for i in range(3000):\n",
    "    r_labels[i][2] = float(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the labels\n",
    "r_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "r_images, r_labels = shuffle(r_images, r_labels, random_state = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42381863,  0.24559314,  0.33323431, ...,  0.32286176,\n",
       "         0.35372255,  0.37860392],\n",
       "       [ 0.53156373,  0.61470882,  0.64574902, ...,  0.83415686,\n",
       "         0.89350784,  0.86481569],\n",
       "       [ 0.24203922,  0.24657549,  0.21022059, ...,  0.54228235,\n",
       "         0.54340196,  0.52687745],\n",
       "       ..., \n",
       "       [ 0.28160098,  0.28735686,  0.29853725, ...,  0.21704412,\n",
       "         0.20153922,  0.18539902],\n",
       "       [ 0.29032451,  0.30502255,  0.33215882, ...,  0.56873725,\n",
       "         0.56399216,  0.84679706],\n",
       "       [ 0.66723333,  0.52322941,  0.17988235, ...,  0.56154608,\n",
       "         0.55193627,  0.51371471]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if they have shuffled\n",
    "r_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Images Done:\n",
    "    - r_images - contain images\n",
    "    - r_lables - contain labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging all images and labels together into 2 seperate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_images_array = np.concatenate((f_images, l_images, r_images), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_array = np.concatenate((f_labels, l_labels, r_labels), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle array to randomize order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20488431,  0.31913235,  0.40438627, ...,  0.93290392,\n",
       "         0.91115392,  0.90059118],\n",
       "       [ 0.16452059,  0.23098333,  0.24517451, ...,  0.45037843,\n",
       "         0.64341667,  0.86788725],\n",
       "       [ 0.52245294,  0.53974706,  0.56372451, ...,  0.88922059,\n",
       "         0.87743824,  0.86189804],\n",
       "       ..., \n",
       "       [ 0.28160098,  0.28735686,  0.29853725, ...,  0.21704412,\n",
       "         0.20153922,  0.18539902],\n",
       "       [ 0.29032451,  0.30502255,  0.33215882, ...,  0.56873725,\n",
       "         0.56399216,  0.84679706],\n",
       "       [ 0.66723333,  0.52322941,  0.17988235, ...,  0.56154608,\n",
       "         0.55193627,  0.51371471]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking states before\n",
    "all_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking states before\n",
    "all_labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "all_images_array, all_labels_array = shuffle(all_images_array, all_labels_array, random_state = 9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62003333,  0.52430588,  0.68951275, ...,  0.52891176,\n",
       "         0.48937647,  0.66167353],\n",
       "       [ 0.31736471,  0.34797255,  0.32738529, ...,  0.62466667,\n",
       "         0.56809804,  0.55606569],\n",
       "       [ 0.04113922,  0.13658039,  0.16118039, ...,  0.47372941,\n",
       "         0.44008039,  0.38227353],\n",
       "       ..., \n",
       "       [ 0.61493627,  0.48115686,  0.42215098, ...,  0.66561863,\n",
       "         0.61916667,  0.57276275],\n",
       "       [ 0.58308529,  0.58470098,  0.55935392, ...,  0.59097059,\n",
       "         0.52669706,  0.56237059],\n",
       "       [ 0.25593529,  0.35657843,  0.32090294, ...,  0.83862549,\n",
       "         0.82238235,  0.80096667]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rechecking states\n",
    "all_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rechecking states\n",
    "all_labels_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Complete Data Set Complete\n",
    "     - all_images_array - contains image data\n",
    "     - all_labels_array - contains label data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving on to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "    - Learning Rate - How quickly we adjust the cost function (tradeoff by setting it to very small vs setting is veyr big)\n",
    "    - Number of epochs - How many training cycles to go through - going through the same data over and over again\n",
    "    - Batch Size - sizes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learning_rate = 0.001\n",
    "learning_rate = 0.000001\n",
    "#training_epochs = 15\n",
    "training_epochs = 8\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Parameters: - Define what the NN or Multi-Layer Perceptron looks like:\n",
    "    - n_classes - ten types of inputs and outputs (0-9)\n",
    "    - n_samples - number of samples in the training data (55000) - can get the number by 'mnist.train.num_examples'\n",
    "    - n_input - what we expect the input to look like - 28x28 flattened vector so 784 inputs going in\n",
    "    - The model will have 2 hidden layers each with 256 nodes:\n",
    "        - n_hidden_1 - number of nuerons in hidden layer 1\n",
    "        - n_hidden_2 - number of neurons in hidden layer 2\n",
    "\n",
    "Why 256?\n",
    "    - Computers have a way of storing image information as 8 bit color storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "#n_samples = 9000\n",
    "n_samples = 1000\n",
    "n_input = 396\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan of Attack:\n",
    "    - First, Recieve input image data array\n",
    "    - Send it to the first hidden layer with weights multiplied and a bias\n",
    "    - Sent to next hidden layer with weights multiplied\n",
    "    - Then sent to output layer\n",
    "    - Calculate the error - Loss Function or Cost Function - How far off the desired result we are?\n",
    "    - Apply optimisation function to try and minimise the cost/error\n",
    "        - This is done by adjusting the weights accordingly across the whole network\n",
    "        - We will be using the adam optimiser\n",
    "            - This depends on the learning rate - the lower the rate, the higher the accuracy but really slow to reach target and after a certian amaount of time - there is no point to lower cost as it has already reached minimum\n",
    "            - The higher the rate, low accuracy, may never converge, may bouce around accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function for a multi-layer perceptron:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:\n",
    "RELU Activtaion function - good from images - rectifier function - either returns an x or 0 - whichever is greater\n",
    "Output layer Activation Function - Linear activation function - matrix multiplication\n",
    "2 hidden layers\n",
    "\n",
    "This function will take 3 arguments:\n",
    "    - x\n",
    "    - Weights\n",
    "    - biases\n",
    "\n",
    "So in the first layer:\n",
    "    - Mutiply all the x and weight values toghether (h1 contains weights for hidden layer 1) (NEEDS TO MATRIX MULTIPLY ALWAYS)\n",
    "    - The add all of the values of each x * weight and the bias summed together.\n",
    "    - Then we pass the value into the RELU Function\n",
    "        - What RELU does: f(x) = max(0,x)\n",
    "        \n",
    "The same as above is going on in the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights,biases):\n",
    "    '''\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: dict of bias values\n",
    "    '''\n",
    "    \n",
    "    ### First Hidden Layer with RELU Activation Function\n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    # RELU(X * W + B) -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    ### Second Hidden Layer\n",
    "    # X * W + B\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    # RELU(X * W + B) -> f(x) = max(0,x)\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    ### Last Output Layer\n",
    "    out_layer = tf.matmul(layer_2,weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights\n",
    "\n",
    "We will now introduce tensorflow variables - This is a modifiable value, can even be modified by computation graph\n",
    "\n",
    "Generally, Model parameter are tensorflow variables\n",
    "\n",
    "REMEMBER: Weights are random to start off with, they will be fined tuned by the NN when calculating the cost/error\n",
    "\n",
    "tf.random_normal - outputs random values from a normal distribution - used to randomly initialise\n",
    "    - tf.random.normal([row, columns]) - creates a matrix of random values, with certain number of rows and columns\n",
    "\n",
    "WHY IS A MATRIX? HOW WILL THE VALUES GET ASSIGNED?\n",
    "    - So the input is 784 different pixel values and the next layer is made of 256 neurons. Each neuron in the input layer will\n",
    "      be connected to all neurons in the next layer and therefore there will be 784*256 weights, therefore assigning each \n",
    "      branch with a weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the weights dictionary\n",
    "'''\n",
    "    h1 - martix of randomly assigned values from a normal distribution. rows=784, columns=256\n",
    "    h2 - martix of randomly assigned values from a normal distribution. rows=256, columns=256\n",
    "    out - matric of randomly assigned values from a normal distribution. rows=256, columns=10\n",
    "'''\n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAIT! What will the output look like:\n",
    "    - Well remeber above we set one-hot to true\n",
    "    - so 0 is represented as [1 0 0 0 0 0 0 0 0 0]\n",
    "         1 is represented as [0 1 0 0 0 0 0 0 0 0]\n",
    "         etc...\n",
    "    - So the output will also be an array like this \n",
    "      EG) it predicts it is 4 so output will be [0 0 0 0 1 0 0 0 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biases are are the same size as the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes])) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set two placeholders for x and y\n",
    "\n",
    "x - The same size as the input as the input is 784 array\n",
    "\n",
    "y - output - will be a 10 element array as there are only 10 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cost and optimiser functions\n",
    "\n",
    "We will use built in tensorflow functions for these parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Stage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Session :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now actually train the model for the number of epochs we defines (15):\n",
    "\n",
    "More Info:\n",
    "    - So basically we get the total batch - 550\n",
    "    - Next we extract the x = the image data and the y = the label for those images correspondingly\n",
    "    - Do the training for that epoch and return the cost\n",
    "    - At the end of 15 loops/epochs - the model has been trained on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Cost 24.7135\n",
      "Epoch: 2 Cost 22.3411\n",
      "Epoch: 3 Cost 18.6679\n",
      "Epoch: 4 Cost 19.3323\n",
      "Epoch: 5 Cost 16.4897\n",
      "Epoch: 6 Cost 17.2408\n",
      "Epoch: 7 Cost 16.1664\n",
      "Epoch: 8 Cost 20.1960\n",
      "Model has completed 8 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "## NEED TO EDIT THE CODE TO INCOPERATE MY OWN BATCH SIZE STUFF\n",
    "start_batch = 0\n",
    "end_batch = batch_size\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    #Cost\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    #Define total_batch as an integer\n",
    "    #9000/100 = 90\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        # Grab the next batch of data using the batch explaination i did above ^^^\n",
    "        #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        batch_x = all_images_array[start_batch:end_batch]\n",
    "        batch_y = all_labels_array[start_batch:end_batch]\n",
    "        \n",
    "        #Optimisation and Loss values - the '_' is a unwanted variable for tuple unpacking\n",
    "        #This will return a loss - which is assigned to 'c'\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "        start_batch += batch_size\n",
    "        end_batch += batch_size\n",
    "        \n",
    "    print(\"Epoch: {} Cost {:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90300024"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x: all_images_array, y: all_labels_array})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SO WHAT HAS HAPPENED?\n",
    "\n",
    "    - So far i keep getting the GPU ran out of memory error (Resource Exhausted)\n",
    "        - To solve this either reduce batch size or reduce number of epochs - i had to do both\n",
    "    - The cost keeps bouncing around - maybe more layers needed / lower learning rat\n",
    "    - The model is evaluated on the training data - same data as trained on giving a 0.998667% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
