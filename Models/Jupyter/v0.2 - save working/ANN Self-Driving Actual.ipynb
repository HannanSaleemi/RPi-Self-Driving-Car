{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network for Self-Driving Car\n",
    "\n",
    "UPDATE - NEW IMAGE SIZES ARE NOW 18X22 (396)\n",
    "\n",
    "UPDATE 2 - Just dome information for you\n",
    "    - I can now implement classes and OOP in my program\n",
    "    - I can turn my whole data preprocessing code into a class to be used multiple times\n",
    "\n",
    "Plan of Attack:\n",
    "    - Import all images from training set:\n",
    "        - Forward, Left and Right Folders\n",
    "    - Resize all the images to 18x22\n",
    "    - Convert images to greyscale:\n",
    "        - Placing the new images in a new array\n",
    "    - Now Reshaping to create a new array which contains flattened images (6336)\n",
    "        - Shape now (3000, 396)\n",
    "    - Add the appropirate labels to each data\n",
    "    - Shuffle the 3 image arrays and the 3 label array corresondingly\n",
    "    - Append all three arrays to a new array:\n",
    "        - One containing all image data\n",
    "        - One containing all labelled data\n",
    "    - Init all TensorFlow variables and constants\n",
    "    - Start an Interative Session\n",
    "    - Start the training:\n",
    "        - Make sure to add saving capabilities\n",
    "    - Once trained and saved - YOU HAVE YOUR MODEL!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf                    #Machine Learning Library\n",
    "import matplotlib.pyplot as plt            #Display the images for verification\n",
    "import numpy as np                         #Mathematical and arrays library\n",
    "from scipy import misc                     #Image Importing module\n",
    "from skimage.transform import resize       #Resizing image module\n",
    "from sklearn.utils import shuffle          #Shuffle in random order module\n",
    "import glob                                #Iterating through all pictures library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greyscale Conversion Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightedAverage(pixel):\n",
    "    return 0.299*pixel[0] + 0.587*pixel[1] + 0.114*pixel[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Array image importing / resizing / convert / reshape / labelling / shuffleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating initial array and resizing\n",
    "f_image_list = []\n",
    "img_count = 0\n",
    "path = 'C:/Users/Hannan Saleemi/Desktop/Self-Driving Car/cardataset/training_set/Forward/'\n",
    "for filename in glob.glob(path+'*.png'):\n",
    "    img_count += 1\n",
    "    image = misc.imread(path+'trainframe ('+str(img_count)+').png')\n",
    "    image_resized = resize(image, (18,22), mode='reflect')\n",
    "    f_image_list.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_resized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dfccbeb3560d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Just confiming the shape of the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image_resized' is not defined"
     ]
    }
   ],
   "source": [
    "#Just confiming the shape of the array\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_resized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5c4efea33b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Converting to greyscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_image_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrownum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_image_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_resized' is not defined"
     ]
    }
   ],
   "source": [
    "#Converting to greyscale\n",
    "f_grey = np.zeros((3000, image_resized.shape[0], image_resized.shape[1]))\n",
    "\n",
    "for image_num in range(len(f_image_list)):\n",
    "    for rownum in range(len(f_image_list[image_num])):\n",
    "        for colnum in range(len(f_image_list[image_num][rownum])):\n",
    "            f_grey[image_num][rownum][colnum] = weightedAverage(f_image_list[image_num][rownum][colnum])\n",
    "    #Output Logging\n",
    "    if image_num % 100 == 0:\n",
    "        print(\"Finished converting image #\", (image_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 18, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the shape of the greyscale array\n",
    "f_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "f_images = f_grey.reshape(3000,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 396)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the new shape again\n",
    "f_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "f_labels = np.zeros(shape=(3000,3))\n",
    "\n",
    "#Adding 3000 forward labels [1,0,0]\n",
    "for i in range(3000):\n",
    "    f_labels[i][0] = float(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the labels\n",
    "f_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "f_images, f_labels = shuffle(f_images, f_labels, random_state = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20488431,  0.31913235,  0.40438627, ...,  0.93290392,\n",
       "         0.91115392,  0.90059118],\n",
       "       [ 0.16452059,  0.23098333,  0.24517451, ...,  0.45037843,\n",
       "         0.64341667,  0.86788725],\n",
       "       [ 0.52245294,  0.53974706,  0.56372451, ...,  0.88922059,\n",
       "         0.87743824,  0.86189804],\n",
       "       ..., \n",
       "       [ 0.12021863,  0.10482941,  0.12077941, ...,  0.52446667,\n",
       "         0.47657353,  0.7271    ],\n",
       "       [ 0.55091176,  0.57213137,  0.62195784, ...,  0.89393235,\n",
       "         0.88511961,  0.87136176],\n",
       "       [ 0.06414314,  0.05195686,  0.09219804, ...,  0.61300686,\n",
       "         0.5555402 ,  0.49911863]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if they have shuffled\n",
    "f_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Images Done:\n",
    "    - f_images - contain images\n",
    "    - f_lables - contain labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Array image importing / resizing / convert / reshape / labelling / shuffleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating initial array and resizing\n",
    "l_image_list = []\n",
    "img_count = 0\n",
    "path = 'C:/Users/Hannan Saleemi/Desktop/Self-Driving Car/cardataset/training_set/Left/'\n",
    "for filename in glob.glob(path+'*.png'):\n",
    "    img_count += 1\n",
    "    image = misc.imread(path+'trainframe ('+str(img_count)+').png')\n",
    "    image_resized = resize(image, (18,22), mode='reflect')\n",
    "    l_image_list.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "#Just confiming the shape of the array\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished converting image # 0\n",
      "Finished converting image # 100\n",
      "Finished converting image # 200\n",
      "Finished converting image # 300\n",
      "Finished converting image # 400\n",
      "Finished converting image # 500\n",
      "Finished converting image # 600\n",
      "Finished converting image # 700\n",
      "Finished converting image # 800\n",
      "Finished converting image # 900\n",
      "Finished converting image # 1000\n",
      "Finished converting image # 1100\n",
      "Finished converting image # 1200\n",
      "Finished converting image # 1300\n",
      "Finished converting image # 1400\n",
      "Finished converting image # 1500\n",
      "Finished converting image # 1600\n",
      "Finished converting image # 1700\n",
      "Finished converting image # 1800\n",
      "Finished converting image # 1900\n",
      "Finished converting image # 2000\n",
      "Finished converting image # 2100\n",
      "Finished converting image # 2200\n",
      "Finished converting image # 2300\n",
      "Finished converting image # 2400\n",
      "Finished converting image # 2500\n",
      "Finished converting image # 2600\n",
      "Finished converting image # 2700\n",
      "Finished converting image # 2800\n",
      "Finished converting image # 2900\n"
     ]
    }
   ],
   "source": [
    "#Converting to greyscale\n",
    "l_grey = np.zeros((3000, image_resized.shape[0], image_resized.shape[1]))\n",
    "\n",
    "for image_num in range(len(l_image_list)):\n",
    "    for rownum in range(len(l_image_list[image_num])):\n",
    "        for colnum in range(len(l_image_list[image_num][rownum])):\n",
    "            l_grey[image_num][rownum][colnum] = weightedAverage(l_image_list[image_num][rownum][colnum])\n",
    "    #Output Logging\n",
    "    if image_num % 100 == 0:\n",
    "        print(\"Finished converting image #\", (image_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 18, 22)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the shape of the greyscale array\n",
    "l_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "l_images = l_grey.reshape(3000,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 396)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the new shape again\n",
    "l_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "l_labels = np.zeros(shape=(3000,3))\n",
    "\n",
    "#Adding 3000 forward labels [1,0,0]\n",
    "for i in range(3000):\n",
    "    l_labels[i][1] = float(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the labels\n",
    "l_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "l_images, l_labels = shuffle(l_images, l_labels, random_state = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20488431,  0.31913235,  0.40438627, ...,  0.93290392,\n",
       "         0.91115392,  0.90059118],\n",
       "       [ 0.16452059,  0.23098333,  0.24517451, ...,  0.45037843,\n",
       "         0.64341667,  0.86788725],\n",
       "       [ 0.52245294,  0.53974706,  0.56372451, ...,  0.88922059,\n",
       "         0.87743824,  0.86189804],\n",
       "       ..., \n",
       "       [ 0.12021863,  0.10482941,  0.12077941, ...,  0.52446667,\n",
       "         0.47657353,  0.7271    ],\n",
       "       [ 0.55091176,  0.57213137,  0.62195784, ...,  0.89393235,\n",
       "         0.88511961,  0.87136176],\n",
       "       [ 0.06414314,  0.05195686,  0.09219804, ...,  0.61300686,\n",
       "         0.5555402 ,  0.49911863]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if they have shuffled\n",
    "f_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Images Done:\n",
    "    - l_images - contain images\n",
    "    - l_lables - contain labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Array image importing / resizing / convert / reshape / labelling / shuffleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating initial array and resizing\n",
    "r_image_list = []\n",
    "img_count = 0\n",
    "path = 'C:/Users/Hannan Saleemi/Desktop/Self-Driving Car/cardataset/training_set/Right/'\n",
    "for filename in glob.glob(path+'*.png'):\n",
    "    img_count += 1\n",
    "    image = misc.imread(path+'trainframe ('+str(img_count)+').png')\n",
    "    image_resized = resize(image, (18,22), mode='reflect')\n",
    "    r_image_list.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "#Just confiming the shape of the array\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished converting image # 0\n",
      "Finished converting image # 100\n",
      "Finished converting image # 200\n",
      "Finished converting image # 300\n",
      "Finished converting image # 400\n",
      "Finished converting image # 500\n",
      "Finished converting image # 600\n",
      "Finished converting image # 700\n",
      "Finished converting image # 800\n",
      "Finished converting image # 900\n",
      "Finished converting image # 1000\n",
      "Finished converting image # 1100\n",
      "Finished converting image # 1200\n",
      "Finished converting image # 1300\n",
      "Finished converting image # 1400\n",
      "Finished converting image # 1500\n",
      "Finished converting image # 1600\n",
      "Finished converting image # 1700\n",
      "Finished converting image # 1800\n",
      "Finished converting image # 1900\n",
      "Finished converting image # 2000\n",
      "Finished converting image # 2100\n",
      "Finished converting image # 2200\n",
      "Finished converting image # 2300\n",
      "Finished converting image # 2400\n",
      "Finished converting image # 2500\n",
      "Finished converting image # 2600\n",
      "Finished converting image # 2700\n",
      "Finished converting image # 2800\n",
      "Finished converting image # 2900\n"
     ]
    }
   ],
   "source": [
    "#Converting to greyscale\n",
    "r_grey = np.zeros((3000, image_resized.shape[0], image_resized.shape[1]))\n",
    "\n",
    "for image_num in range(len(r_image_list)):\n",
    "    for rownum in range(len(r_image_list[image_num])):\n",
    "        for colnum in range(len(r_image_list[image_num][rownum])):\n",
    "            r_grey[image_num][rownum][colnum] = weightedAverage(r_image_list[image_num][rownum][colnum])\n",
    "    #Output Logging\n",
    "    if image_num % 100 == 0:\n",
    "        print(\"Finished converting image #\", (image_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 18, 22)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the shape of the greyscale array\n",
    "r_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "r_images = r_grey.reshape(3000,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 396)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the new shape again\n",
    "r_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "r_labels = np.zeros(shape=(3000,3))\n",
    "\n",
    "#Adding 3000 forward labels [1,0,0]\n",
    "for i in range(3000):\n",
    "    r_labels[i][2] = float(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the labels\n",
    "r_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "r_images, r_labels = shuffle(r_images, r_labels, random_state = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42381863,  0.24559314,  0.33323431, ...,  0.32286176,\n",
       "         0.35372255,  0.37860392],\n",
       "       [ 0.53156373,  0.61470882,  0.64574902, ...,  0.83415686,\n",
       "         0.89350784,  0.86481569],\n",
       "       [ 0.24203922,  0.24657549,  0.21022059, ...,  0.54228235,\n",
       "         0.54340196,  0.52687745],\n",
       "       ..., \n",
       "       [ 0.28160098,  0.28735686,  0.29853725, ...,  0.21704412,\n",
       "         0.20153922,  0.18539902],\n",
       "       [ 0.29032451,  0.30502255,  0.33215882, ...,  0.56873725,\n",
       "         0.56399216,  0.84679706],\n",
       "       [ 0.66723333,  0.52322941,  0.17988235, ...,  0.56154608,\n",
       "         0.55193627,  0.51371471]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if they have shuffled\n",
    "r_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Images Done:\n",
    "    - r_images - contain images\n",
    "    - r_lables - contain labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging all images and labels together into 2 seperate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_images_array = np.concatenate((f_images, l_images, r_images), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_labels_array = np.concatenate((f_labels, l_labels, r_labels), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle array to randomize order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20488431,  0.31913235,  0.40438627, ...,  0.93290392,\n",
       "         0.91115392,  0.90059118],\n",
       "       [ 0.16452059,  0.23098333,  0.24517451, ...,  0.45037843,\n",
       "         0.64341667,  0.86788725],\n",
       "       [ 0.52245294,  0.53974706,  0.56372451, ...,  0.88922059,\n",
       "         0.87743824,  0.86189804],\n",
       "       ..., \n",
       "       [ 0.28160098,  0.28735686,  0.29853725, ...,  0.21704412,\n",
       "         0.20153922,  0.18539902],\n",
       "       [ 0.29032451,  0.30502255,  0.33215882, ...,  0.56873725,\n",
       "         0.56399216,  0.84679706],\n",
       "       [ 0.66723333,  0.52322941,  0.17988235, ...,  0.56154608,\n",
       "         0.55193627,  0.51371471]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking states before\n",
    "all_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking states before\n",
    "all_labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "all_images_array, all_labels_array = shuffle(all_images_array, all_labels_array, random_state = 9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62003333,  0.52430588,  0.68951275, ...,  0.52891176,\n",
       "         0.48937647,  0.66167353],\n",
       "       [ 0.31736471,  0.34797255,  0.32738529, ...,  0.62466667,\n",
       "         0.56809804,  0.55606569],\n",
       "       [ 0.04113922,  0.13658039,  0.16118039, ...,  0.47372941,\n",
       "         0.44008039,  0.38227353],\n",
       "       ..., \n",
       "       [ 0.61493627,  0.48115686,  0.42215098, ...,  0.66561863,\n",
       "         0.61916667,  0.57276275],\n",
       "       [ 0.58308529,  0.58470098,  0.55935392, ...,  0.59097059,\n",
       "         0.52669706,  0.56237059],\n",
       "       [ 0.25593529,  0.35657843,  0.32090294, ...,  0.83862549,\n",
       "         0.82238235,  0.80096667]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rechecking states\n",
    "all_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rechecking states\n",
    "all_labels_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Complete Data Set Complete\n",
    "     - all_images_array - contains image data\n",
    "     - all_labels_array - contains label data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving on to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "    - Learning Rate - How quickly we adjust the cost function (tradeoff by setting it to very small vs setting is veyr big)\n",
    "    - Number of epochs - How many training cycles to go through - going through the same data over and over again\n",
    "    - Batch Size - sizes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learning_rate = 0.001\n",
    "learning_rate = 0.000001\n",
    "#training_epochs = 15\n",
    "training_epochs = 9\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Parameters: - Define what the NN or Multi-Layer Perceptron looks like:\n",
    "    - n_classes - ten types of inputs and outputs (0-9)\n",
    "    - n_samples - number of samples in the training data (55000) - can get the number by 'mnist.train.num_examples'\n",
    "    - n_input - what we expect the input to look like - 28x28 flattened vector so 784 inputs going in\n",
    "    - The model will have 2 hidden layers each with 256 nodes:\n",
    "        - n_hidden_1 - number of nuerons in hidden layer 1\n",
    "        - n_hidden_2 - number of neurons in hidden layer 2\n",
    "\n",
    "Why 256?\n",
    "    - Computers have a way of storing image information as 8 bit color storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "#n_samples = 9000\n",
    "n_samples = 1000\n",
    "n_input = 396\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan of Attack:\n",
    "    - First, Recieve input image data array\n",
    "    - Send it to the first hidden layer with weights multiplied and a bias\n",
    "    - Sent to next hidden layer with weights multiplied\n",
    "    - Then sent to output layer\n",
    "    - Calculate the error - Loss Function or Cost Function - How far off the desired result we are?\n",
    "    - Apply optimisation function to try and minimise the cost/error\n",
    "        - This is done by adjusting the weights accordingly across the whole network\n",
    "        - We will be using the adam optimiser\n",
    "            - This depends on the learning rate - the lower the rate, the higher the accuracy but really slow to reach target and after a certian amaount of time - there is no point to lower cost as it has already reached minimum\n",
    "            - The higher the rate, low accuracy, may never converge, may bouce around accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function for a multi-layer perceptron:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:\n",
    "RELU Activtaion function - good from images - rectifier function - either returns an x or 0 - whichever is greater\n",
    "Output layer Activation Function - Linear activation function - matrix multiplication\n",
    "2 hidden layers\n",
    "\n",
    "This function will take 3 arguments:\n",
    "    - x\n",
    "    - Weights\n",
    "    - biases\n",
    "\n",
    "So in the first layer:\n",
    "    - Mutiply all the x and weight values toghether (h1 contains weights for hidden layer 1) (NEEDS TO MATRIX MULTIPLY ALWAYS)\n",
    "    - The add all of the values of each x * weight and the bias summed together.\n",
    "    - Then we pass the value into the RELU Function\n",
    "        - What RELU does: f(x) = max(0,x)\n",
    "        \n",
    "The same as above is going on in the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights,biases):\n",
    "    '''\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: dict of bias values\n",
    "    '''\n",
    "    \n",
    "    ### First Hidden Layer with RELU Activation Function\n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    # RELU(X * W + B) -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    ### Second Hidden Layer\n",
    "    # X * W + B\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    # RELU(X * W + B) -> f(x) = max(0,x)\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    ### Last Output Layer\n",
    "    out_layer = tf.matmul(layer_2,weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights\n",
    "\n",
    "We will now introduce tensorflow variables - This is a modifiable value, can even be modified by computation graph\n",
    "\n",
    "Generally, Model parameter are tensorflow variables\n",
    "\n",
    "REMEMBER: Weights are random to start off with, they will be fined tuned by the NN when calculating the cost/error\n",
    "\n",
    "tf.random_normal - outputs random values from a normal distribution - used to randomly initialise\n",
    "    - tf.random.normal([row, columns]) - creates a matrix of random values, with certain number of rows and columns\n",
    "\n",
    "WHY IS A MATRIX? HOW WILL THE VALUES GET ASSIGNED?\n",
    "    - So the input is 784 different pixel values and the next layer is made of 256 neurons. Each neuron in the input layer will\n",
    "      be connected to all neurons in the next layer and therefore there will be 784*256 weights, therefore assigning each \n",
    "      branch with a weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the weights dictionary\n",
    "'''\n",
    "    h1 - martix of randomly assigned values from a normal distribution. rows=784, columns=256\n",
    "    h2 - martix of randomly assigned values from a normal distribution. rows=256, columns=256\n",
    "    out - matric of randomly assigned values from a normal distribution. rows=256, columns=10\n",
    "'''\n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAIT! What will the output look like:\n",
    "    - Well remeber above we set one-hot to true\n",
    "    - so 0 is represented as [1 0 0 0 0 0 0 0 0 0]\n",
    "         1 is represented as [0 1 0 0 0 0 0 0 0 0]\n",
    "         etc...\n",
    "    - So the output will also be an array like this \n",
    "      EG) it predicts it is 4 so output will be [0 0 0 0 1 0 0 0 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biases are are the same size as the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes])) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set two placeholders for x and y\n",
    "\n",
    "x - The same size as the input as the input is 784 array\n",
    "\n",
    "y - output - will be a 10 element array as there are only 10 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cost and optimiser functions\n",
    "\n",
    "We will use built in tensorflow functions for these parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Stage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Session :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now actually train the model for the number of epochs we defines (15):\n",
    "\n",
    "More Info:\n",
    "    - So basically we get the total batch - 550\n",
    "    - Next we extract the x = the image data and the y = the label for those images correspondingly\n",
    "    - Do the training for that epoch and return the cost\n",
    "    - At the end of 15 loops/epochs - the model has been trained on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Cost 5.0027\n",
      "Epoch: 2 Cost 7.5861\n",
      "Epoch: 3 Cost 5.1679\n",
      "Epoch: 4 Cost 6.6307\n",
      "Epoch: 5 Cost 5.9929\n",
      "Epoch: 6 Cost 6.9790\n",
      "Epoch: 7 Cost 5.5080\n",
      "Epoch: 8 Cost 5.4742\n",
      "Epoch: 9 Cost 4.7297\n",
      "Model has completed 9 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "start_batch = 0\n",
    "end_batch = batch_size\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    #Cost\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    #Define total_batch as an integer\n",
    "    #9000/100 = 90\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        # Grab the next batch of data using the batch explaination i did above ^^^\n",
    "        #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        batch_x = all_images_array[start_batch:end_batch]\n",
    "        batch_y = all_labels_array[start_batch:end_batch]\n",
    "        \n",
    "        #Optimisation and Loss values - the '_' is a unwanted variable for tuple unpacking\n",
    "        #This will return a loss - which is assigned to 'c'\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "        start_batch += batch_size\n",
    "        end_batch += batch_size\n",
    "        \n",
    "    print(\"Epoch: {} Cost {:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"C:/Users/Hannan Saleemi/Documents/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94722253"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x: all_images_array, y: all_labels_array})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SO WHAT HAS HAPPENED?\n",
    "\n",
    "    - So far i keep getting the GPU ran out of memory error (Resource Exhausted)\n",
    "        - To solve this either reduce batch size or reduce number of epochs - i had to do both\n",
    "    - The cost keeps bouncing around - maybe more layers needed / lower learning rat\n",
    "    - The model is evaluated on the training data - same data as trained on giving a 0.998667% accuracy\n",
    "    \n",
    "    - Maybe increase batch size and increase epochs\n",
    "    - or decarese batch size and increase epochs\n",
    "    - play around to avoid GPU Memory Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Apparently - i can reset GPU Memory anytime by calling this function:\n",
    "\n",
    "Best to reset GPU Memory after 8 epochs\n",
    "DOESN'T WORK - K is not defined!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_GPU_mem():\n",
    "    K.get_session()\n",
    "    cfg = K.tf.ConfigProto()\n",
    "    cfg.gpu_options.allow.growth = True\n",
    "    K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets test a prediction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_test = np.zeros(shape=(396))\n",
    "array_test = all_images_array[2400].reshape(1,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has predicted: Forward\n"
     ]
    }
   ],
   "source": [
    "result = sess.run(tf.argmax(pred, 1), feed_dict={x: array_test})\n",
    "if result == [2]:\n",
    "    print(\"Model has predicted: Right\")\n",
    "elif result == [1]:\n",
    "    print(\"Model has predicted: Left\")\n",
    "elif result == [0]:\n",
    "    print(\"Model has predicted: Forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw_img = all_images_array[2400].reshape(18,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS8AAAD8CAYAAAAmAyLtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEslJREFUeJzt3X9sXfV5x/HPg38EJ3Ec20AS8oMQRIOyaoMprVjWdTBY\nRVlZijQmkIJoQMqYgAGKQJT9AQhNqrKuLbDSiZUsoGWg0kILg21l0NJNYtCQ0hISCvlBfhFwyA/H\nQOKfz/7wDTghtu9z7rnn5mu/X1IU+/rj6+/x8X107j33OY+5uwAgNSfUegEAkAXFC0CSKF4AkkTx\nApAkiheAJFG8ACSJ4gUgSRQvAEmieAFIUn2RP6y9vd3nzJlTdt7Mqrgaaf/+/aF8c3NzKJ9l/YcO\nHQrlJ0+eHP4ZEQMDA1W9/2rv42qL/n6q/fuUpIaGhlD+eOuyWbt27fvufvJouUKL15w5c/TCCy+U\nna+vr+7ynnjiiVD+wgsvDOVPOCF+YPvmm2+G8osWLQrlo3+o0WLa398fykcfaNG/iWoXl4MHD4by\nH330USifxamnnhrKR/dZNB99HDQ2Nm4t635D9woAx4mKipeZXWRmvzWzjWZ2W16LAoDRZC5eZlYn\n6buSvixpgaQrzGxBXgsDgJFUcuT1eUkb3X2zu/dIelTS4nyWBQAjq6R4zZS0fcjnO0q3HcHMlpnZ\nGjNbs2fPngp+HAB8ouov2Lv7A+6+0N0Xtre3V/vHARgnKileOyXNHvL5rNJtAFB1lRSvX0o608xO\nN7NGSZdLejKfZQHAyDK/C9Td+8zsekn/JalO0kp3fz23lQHACCp6C7u7PyPpmZzWAgBlK7Q9SIq1\np0RbNaJ9cp2dnaH8ww8/HMpnOUExffr08PdERNuDGhsbQ/lo60hvb28oH93H0daUaLtS9PfT0tIS\nyhch2nJV7ba9ctEeBCBJFC8ASaJ4AUgSxQtAkiheAJJE8QKQJIoXgCRRvAAkieIFIEkULwBJongB\nSFKhTUp9fX2KXE012scWHSsVncM4f/78UD7L6LO+vr5QfvPmzaH87t27Q/mTTx51fN4Rurq6Qvno\neqZNmxbKNzU1hfITJ04M5aNzM7P0BUa/J/q4Od7y5eLIC0CSKF4AklTJ6LPZZvYzM1tvZq+b2Y15\nLgwARlLJa159kpa7+1oza5b0ipk96+7rc1obAAwr85GXu+9y97Wlj7skbdAxRp8BQDXk8pqXmc2V\ndI6kl/K4PwAYTcXFy8wmS/qRpJvc/cAxvv7x0Nm9e/dW+uMAQFKFxcvMGjRYuFa7++PHygwdOtvW\n1lbJjwOAj1VyttEkPShpg7t/K78lAcDoKjny+kNJV0r6EzN7tfTv4pzWBQAjqmTo7P9Kqs77/gFg\nFIX2Nvb29mrXrl1l56MzAKMzCaN9bB0dHaH8wYMHQ3kpPqvyzjvvDOW7u7tD+Whf3c033xzKHzp0\nKJTfsmVLKL9+fexth88//3woH53beN9994XyklRXV1fVfLQHt6enJ5TPss3loD0IQJIoXgCSRPEC\nkCSKF4AkUbwAJIniBSBJFC8ASaJ4AUgSxQtAkiheAJJE8QKQpEJ7GwcGBkKzFas9tzF6ccRoT9fT\nTz8dykvSpk2bQvlor2K0d/LWW28N5SdNmhTKR/tFo3MtZ86MXZk8up7o3MYrr7wylJek5cuXh/LR\nfdDa2hrKR11yySWh/OrVq8vKceQFIEkULwBJyuMa9nVm9isz+/c8FgQA5cjjyOtGDY49A4DCVDqA\nY5akP5P0/XyWAwDlqfTI6zuSbpUUO4UFABWqZHrQVyR1uPsro+Q+ntvY2dmZ9ccBwBEqnR7052b2\ntqRHNThF6F+PDg2d29jS0lLBjwOAT2QuXu7+dXef5e5zJV0u6Xl3X5LbygBgBLzPC0CScmkPcvef\nS/p5HvcFAOXgyAtAkgptzJZig2S7urpC9x0d8vrhhx+G8itWrAjlo43lWb4nOmh30aJFoXx0KOya\nNWtC+WgzfXTIa3SganR7o/noQFhJuuuuu0L5W265JZSv9jZkeRyUgyMvAEmieAFIEsULQJIoXgCS\nRPECkCSKF4AkUbwAJIniBSBJFC8ASaJ4AUgSxQtAkgrtbezv7w/1K0Z7FV988cVQ/qmnngrle3t7\nQ/loX12W74n2Ni5cuDCU379/fygfHWDa1NQUyq9bty6Unz59eih/7bXXhvL33HNPKJ+lzy/6d3f3\n3XeH8kuXLg3lJ0yYEMrPnj07lC8XR14AklTp9KCpZvZDM3vDzDaY2R/ktTAAGEmlTxvvkfSf7v4X\nZtYoaWIOawKAUWUuXmbWIumLkr4mSe7eI6knn2UBwMgqedp4uqTdkv7FzH5lZt83s0k5rQsARlRJ\n8aqX9PuSvufu50j6UNJtR4eGzm08cOBABT8OAD5RSfHaIWmHu79U+vyHGixmRxg6t3HKlCkV/DgA\n+EQlcxvflbTdzOaXbrpA0vpcVgUAo6j0bOMNklaXzjRulhR7txsAZFRR8XL3VyXF3rINADngHfYA\nklT43MaBgYGys9F5ddH5c93d3aF8X19fKJ+ljy3a23j77beH8g0NDaF8W1tbKP/BBx+E8lEzZ84M\n5aNzHjs7O0P5Ivpdo/2r9fWxh/WqVatC+csuuyyUj66nXBx5AUgSxQtAkiheAJJE8QKQJIoXgCRR\nvAAkieIFIEkULwBJongBSBLFC0CSKF4AkmTRvqlKNDU1+dy5c8vOR+c29vTELqFf7Xykj/OwqVOn\nhvLXX399KB/9nZ5yyimh/Pbt20P5aG/gxImxGS/R+4/OJIz2x65YsSKUl+K9jdGe2rq6ulD+xBNP\nDOUXLFgQyr/88suvuPuoV6vhyAtAkiqd23izmb1uZuvM7BEzi5VkAMgoc/Eys5mS/kbSQnf/rKQ6\nSZfntTAAGEmlTxvrJTWZWb0GB86+U/mSAGB0lQzg2Cnpm5K2SdolqdPdf5rXwgBgJJU8bWyVtFiD\nw2dPlTTJzJYcI/fx3MbolUgBYDiVPG28UNIWd9/t7r2SHpe06OjQ0LmN1bocLIDxp5LitU3SuWY2\n0QbfWHKBpA35LAsARlbJa14vaXBK9lpJr5Xu64Gc1gUAI6p0buMdku7IaS0AUDbeYQ8gSYW+gu7u\noV6z6NnJaB9btPcwS69i1DXXXBPK79mzJ5SPzg3cunVrKD9lypRQ/sCBA6H8xo0bQ/loH95pp50W\nykfnVGaZ5RntPYzu4+j9R7chus/KxZEXgCRRvAAkieIFIEkULwBJongBSBLFC0CSKF4AkkTxApAk\niheAJFG8ACSJ4gUgSYX3Nkb6A6s9U7La8/BuuummUF6K95lFewl37doVyre3t4fy27ZtC+UXLhx1\nPN8R2traQvlNmzaF8tG5ltF+2uuuuy6Ul6T7778/lC9yFmstceQFIEkULwBJGrV4mdlKM+sws3VD\nbmszs2fN7K3S/63VXSYAHKmcI69Vki466rbbJD3n7mdKeq70OQAUZtTi5e6/kLT3qJsXS3qo9PFD\nkr6a87oAYERZzzZOc/fDp63elTRtuKCZLZO0TIqfSQOA4VT8gr0Pnpcd9tzs0LmNFC8AeclavN4z\nsxmSVPq/I78lAcDoshavJyVdVfr4Kkk/yWc5AFCect4q8YikFyXNN7MdZnaNpG9I+lMze0vShaXP\nAaAwo75g7+5XDPOlC3JeCwCUrdDeRqm6fVfReXXRtUTzXV1dobwk7d69O5SfNm3YE7256OnpCeXn\nzZsXykd7D5ubm0P5yZMnh/LROZJR1b7/LKr9OKjWY572IABJongBSBLFC0CSKF4AkkTxApAkiheA\nJFG8ACSJ4gUgSRQvAEmieAFIEsULQJKsyBlvEyZM8FmzZpWdP3ToUOj+u7u7Q/nIDElJWrp0aSjf\n398fykvxXsLoBR6j/Z/R+3/nnXdC+YaGhlA+uv6+vr5QPvo3d8YZZ4Ty+/btC+UlqaWlJZS/9957\nQ/n6+liLc/RvIrqP9+3b94q7jzrQkyMvAEmieAFIUta5jX9vZm+Y2W/M7Akzm1rdZQLAkbLObXxW\n0mfd/XclvSnp6zmvCwBGlGluo7v/1N0PvxL6f5LKfxUeAHKQx2teV0v6j+G+aGbLzGyNma2Jnt0D\ngOFUVLzM7G8l9UlaPVxm6NzG6GluABhO5mvYm9nXJH1F0gVe5JvFAEAZi5eZXSTpVkl/7O4f5bsk\nABhd1rmN/yipWdKzZvaqmf1TldcJAEfIOrfxwSqsBQDKVvjcxmqecTSzquajPWDvv/9+KC9JbW1t\noXy0Fy/6++/s7Azlo1pbW0P5pqamUL7av5/oPo72rkrxuYdTpkwJ5Q8ePBjKR3sbo4+zcnH6D0CS\nKF4AkkTxApAkiheAJFG8ACSJ4gUgSRQvAEmieAFIEsULQJIoXgCSRPECkCSKF4AkFd6YXU3Rxumr\nr746lJ8wYUIoHx14KsUH50aHmM6YMSOU37NnTyg/dWpskFR0eydNmhTKd3V1hfLRfRxtao42TUvx\nNS1ZsiSUX7lyZShf7QsglIsjLwBJyjS3ccjXlpuZm9lJ1VkeABxb1rmNMrPZkr4kaVvOawKAUWWa\n21jybQ1ex57hGwAKl+k1LzNbLGmnu/865/UAQFnCZxvNbKKk2zX4lLGc/DJJy6T45WMBYDhZjrzO\nkHS6pF+b2duSZklaa2bTjxUeOnSW4gUgL+EjL3d/TdIphz8vFbCF7h6fNgEAGWWd2wgANZV1buPQ\nr8/NbTUAUCbeYQ8gSYX3Np5wQvn1MtoTddZZZ4Xy0Z6xaJ/c7NmzQ3kpPsQ0+juq9v3PmTMnlN+4\ncWMov3///lC+oaEhlI+eVOrt7Q3lo/23UrxHNvIYy5Lv7++v6v2Xfb9VuVcAqDKKF4AkUbwAJIni\nBSBJFC8ASaJ4AUgSxQtAkiheAJJE8QKQJIoXgCRRvAAkqdDeRjML9Y5F+8AuvvjiUL6pqSmU3759\neyjf3NwcykvxPrBof2a0Ly26DVu2bAnlo72HnZ2doXxra2so39jYGMpH51RG/+YkqaOjI5SfPv2Y\n1wUd1hVXjHjhmE957LHHQvnoPi4XR14AkpR5bqOZ3WBmb5jZ62a2onpLBIBPyzS30czOl7RY0u+5\n++9I+mb+SwOA4WWd2/jXkr7h7t2lTOxJOQBUKOtrXp+R9Edm9pKZvWBmn8tzUQAwmqxnG+sltUk6\nV9LnJP3AzOa5+6emZw+d25jlKpIAcCxZj7x2SHrcB70saUDSSccKMrcRQDVkLV4/lnS+JJnZZyQ1\nSmJuI4DCjPo8rjS38TxJJ5nZDkl3SFopaWXp7RM9kq461lNGAKiWSuY2Lsl5LQBQNt5hDyBJx3Vv\n46WXXhq+/4ju7u5QPtr3Fp23J0mTJ08O5aPbEO0N3Lv36Lf4jSy6ze3t7aH8jBkzQvmJEyeG8tHf\nz4EDB0L5lpaWUF6K909G+12jsyfnz58fym/dujWULxdHXgCSRPECkCSKF4AkUbwAJIniBSBJFC8A\nSaJ4AUgSxQtAkiheAJJE8QKQJIoXgCRZkVeyMbPdko7V6HSSxtf1wMbb9krjb5vH2/ZK+W3zae5+\n8mihQovXsIswW+PuC2u9jqKMt+2Vxt82j7ftlYrfZp42AkgSxQtAko6X4vVArRdQsPG2vdL42+bx\ntr1Swdt8XLzmBQBRx8uRFwCE1LR4mdlFZvZbM9toZrfVci1FMbO3zew1M3vVzNbUej3VYGYrzayj\nNF3q8G1tZvasmb1V+r+1lmvM0zDbe6eZ7Szt51fN7OJarjFPZjbbzH5mZuvN7HUzu7F0e6H7uGbF\ny8zqJH1X0pclLZB0hZktqNV6Cna+u589hk+lr5J00VG33SbpOXc/U9Jzpc/HilX69PZK0rdL+/ls\nd3+m4DVVU5+k5e6+QNK5kq4rPXYL3ce1PPL6vKSN7r7Z3XskPSppcQ3Xg5y4+y8kHT25Y7Gkh0of\nPyTpq4UuqoqG2d4xy913ufva0sddkjZImqmC93Eti9dMSduHfL6jdNtY55L+28xeMbNltV5Mgaa5\n+67Sx+9KmlbLxRTkBjP7Telp5Zh5mjyUmc2VdI6kl1TwPuYF++J9wd3P1uDT5evM7Iu1XlDRStPV\nx/pp7u9JmifpbEm7JP1DbZeTPzObLOlHkm5y9yNmwBWxj2tZvHZKmj3k81ml28Y0d99Z+r9D0hMa\nfPo8HrxnZjMkqfR/R43XU1Xu/p6797v7gKR/1hjbz2bWoMHCtdrdHy/dXOg+rmXx+qWkM83sdDNr\nlHS5pCdruJ6qM7NJZtZ8+GNJX5K0buTvGjOelHRV6eOrJP2khmupusMP4pJLNYb2sw1Od35Q0gZ3\n/9aQLxW6j2v6JtXS6ePvSKqTtNLd/65miymAmc3T4NGWNDit/N/G4jab2SOSztPgVQbek3SHpB9L\n+oGkORq8sshfuvuYeJF7mO09T4NPGV3S25L+asjrQUkzsy9I+h9Jr0kaKN18uwZf9ypsH/MOewBJ\n4gV7AEmieAFIEsULQJIoXgCSRPECkCSKF4AkUbwAJIniBSBJ/w9yi3dFjwFcuAAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f052e2cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(draw_img, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
