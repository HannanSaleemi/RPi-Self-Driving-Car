{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network for Self-Driving Car\n",
    "\n",
    "UPDATE - NEW IMAGE SIZES ARE NOW 18X22 (396)\n",
    "\n",
    "UPDATE 2 - Just dome information for you\n",
    "    - I can now implement classes and OOP in my program\n",
    "    - I can turn my whole data preprocessing code into a class to be used multiple times\n",
    "\n",
    "Plan of Attack:\n",
    "    - Import all images from training set:\n",
    "        - Forward, Left and Right Folders\n",
    "    - Resize all the images to 18x22\n",
    "    - Convert images to greyscale:\n",
    "        - Placing the new images in a new array\n",
    "    - Now Reshaping to create a new array which contains flattened images (6336)\n",
    "        - Shape now (3000, 396)\n",
    "    - Add the appropirate labels to each data\n",
    "    - Shuffle the 3 image arrays and the 3 label array corresondingly\n",
    "    - Append all three arrays to a new array:\n",
    "        - One containing all image data\n",
    "        - One containing all labelled data\n",
    "    - Init all TensorFlow variables and constants\n",
    "    - Start an Interative Session\n",
    "    - Start the training:\n",
    "        - Make sure to add saving capabilities\n",
    "    - Once trained and saved - YOU HAVE YOUR MODEL!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf                    #Machine Learning Library\n",
    "import matplotlib.pyplot as plt            #Display the images for verification\n",
    "import numpy as np                         #Mathematical and arrays library\n",
    "from scipy import misc                     #Image Importing module\n",
    "from skimage.transform import resize       #Resizing image module\n",
    "from sklearn.utils import shuffle          #Shuffle in random order module\n",
    "import glob                                #Iterating through all pictures library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greyscale Conversion Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weightedAverage(pixel):\n",
    "    return 0.299*pixel[0] + 0.587*pixel[1] + 0.114*pixel[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Array image importing / resizing / convert / reshape / labelling / shuffleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating initial array and resizing\n",
    "f_image_list = []\n",
    "img_count = 0\n",
    "path = \"/Users/hannansaleemi/Desktop/SDC/Jupyter Notebook Examples/cardataset/training_set/Forward/\"\n",
    "for filename in glob.glob(path+'*.png'):\n",
    "    img_count += 1\n",
    "    image = misc.imread(path+'trainframe ('+str(img_count)+').png')\n",
    "    image_resized = resize(image, (18,22), mode='reflect')\n",
    "    f_image_list.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_resized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dfccbeb3560d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Just confiming the shape of the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image_resized' is not defined"
     ]
    }
   ],
   "source": [
    "#Just confiming the shape of the array\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_resized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5c4efea33b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Converting to greyscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf_grey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_resized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_image_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrownum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_image_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_resized' is not defined"
     ]
    }
   ],
   "source": [
    "#Converting to greyscale\n",
    "f_grey = np.zeros((3000, image_resized.shape[0], image_resized.shape[1]))\n",
    "\n",
    "for image_num in range(len(f_image_list)):\n",
    "    for rownum in range(len(f_image_list[image_num])):\n",
    "        for colnum in range(len(f_image_list[image_num][rownum])):\n",
    "            f_grey[image_num][rownum][colnum] = weightedAverage(f_image_list[image_num][rownum][colnum])\n",
    "    #Output Logging\n",
    "    if image_num % 100 == 0:\n",
    "        print(\"Finished converting image #\", (image_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_grey' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fc0465e89f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Just checking the shape of the greyscale array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf_grey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f_grey' is not defined"
     ]
    }
   ],
   "source": [
    "#Just checking the shape of the greyscale array\n",
    "f_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "f_images = f_grey.reshape(3000,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 396)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the new shape again\n",
    "f_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "f_labels = np.zeros(shape=(3000,3))\n",
    "\n",
    "#Adding 3000 forward labels [1,0,0]\n",
    "for i in range(3000):\n",
    "    f_labels[i][0] = float(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the labels\n",
    "f_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "f_images, f_labels = shuffle(f_images, f_labels, random_state = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20488431,  0.31913235,  0.40438627, ...,  0.93290392,\n",
       "         0.91115392,  0.90059118],\n",
       "       [ 0.16452059,  0.23098333,  0.24517451, ...,  0.45037843,\n",
       "         0.64341667,  0.86788725],\n",
       "       [ 0.52245294,  0.53974706,  0.56372451, ...,  0.88922059,\n",
       "         0.87743824,  0.86189804],\n",
       "       ..., \n",
       "       [ 0.12021863,  0.10482941,  0.12077941, ...,  0.52446667,\n",
       "         0.47657353,  0.7271    ],\n",
       "       [ 0.55091176,  0.57213137,  0.62195784, ...,  0.89393235,\n",
       "         0.88511961,  0.87136176],\n",
       "       [ 0.06414314,  0.05195686,  0.09219804, ...,  0.61300686,\n",
       "         0.5555402 ,  0.49911863]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if they have shuffled\n",
    "f_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Images Done:\n",
    "    - f_images - contain images\n",
    "    - f_lables - contain labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Array image importing / resizing / convert / reshape / labelling / shuffleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating initial array and resizing\n",
    "l_image_list = []\n",
    "img_count = 0\n",
    "path = \"/Users/hannansaleemi/Desktop/SDC/Jupyter Notebook Examples/cardataset/training_set/Left/\"\n",
    "for filename in glob.glob(path+'*.png'):\n",
    "    img_count += 1\n",
    "    image = misc.imread(path+'trainframe ('+str(img_count)+').png')\n",
    "    image_resized = resize(image, (18,22), mode='reflect')\n",
    "    l_image_list.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "#Just confiming the shape of the array\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished converting image # 0\n",
      "Finished converting image # 100\n",
      "Finished converting image # 200\n",
      "Finished converting image # 300\n",
      "Finished converting image # 400\n",
      "Finished converting image # 500\n",
      "Finished converting image # 600\n",
      "Finished converting image # 700\n",
      "Finished converting image # 800\n",
      "Finished converting image # 900\n",
      "Finished converting image # 1000\n",
      "Finished converting image # 1100\n",
      "Finished converting image # 1200\n",
      "Finished converting image # 1300\n",
      "Finished converting image # 1400\n",
      "Finished converting image # 1500\n",
      "Finished converting image # 1600\n",
      "Finished converting image # 1700\n",
      "Finished converting image # 1800\n",
      "Finished converting image # 1900\n",
      "Finished converting image # 2000\n",
      "Finished converting image # 2100\n",
      "Finished converting image # 2200\n",
      "Finished converting image # 2300\n",
      "Finished converting image # 2400\n",
      "Finished converting image # 2500\n",
      "Finished converting image # 2600\n",
      "Finished converting image # 2700\n",
      "Finished converting image # 2800\n",
      "Finished converting image # 2900\n"
     ]
    }
   ],
   "source": [
    "#Converting to greyscale\n",
    "l_grey = np.zeros((3000, image_resized.shape[0], image_resized.shape[1]))\n",
    "\n",
    "for image_num in range(len(l_image_list)):\n",
    "    for rownum in range(len(l_image_list[image_num])):\n",
    "        for colnum in range(len(l_image_list[image_num][rownum])):\n",
    "            l_grey[image_num][rownum][colnum] = weightedAverage(l_image_list[image_num][rownum][colnum])\n",
    "    #Output Logging\n",
    "    if image_num % 100 == 0:\n",
    "        print(\"Finished converting image #\", (image_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 18, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the shape of the greyscale array\n",
    "l_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "l_images = l_grey.reshape(3000,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 396)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the new shape again\n",
    "l_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "l_labels = np.zeros(shape=(3000,3))\n",
    "\n",
    "#Adding 3000 forward labels [1,0,0]\n",
    "for i in range(3000):\n",
    "    l_labels[i][1] = float(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the labels\n",
    "l_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "l_images, l_labels = shuffle(l_images, l_labels, random_state = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20488431,  0.31913235,  0.40438627, ...,  0.93290392,\n",
       "         0.91115392,  0.90059118],\n",
       "       [ 0.16452059,  0.23098333,  0.24517451, ...,  0.45037843,\n",
       "         0.64341667,  0.86788725],\n",
       "       [ 0.52245294,  0.53974706,  0.56372451, ...,  0.88922059,\n",
       "         0.87743824,  0.86189804],\n",
       "       ..., \n",
       "       [ 0.12021863,  0.10482941,  0.12077941, ...,  0.52446667,\n",
       "         0.47657353,  0.7271    ],\n",
       "       [ 0.55091176,  0.57213137,  0.62195784, ...,  0.89393235,\n",
       "         0.88511961,  0.87136176],\n",
       "       [ 0.06414314,  0.05195686,  0.09219804, ...,  0.61300686,\n",
       "         0.5555402 ,  0.49911863]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if they have shuffled\n",
    "f_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left Images Done:\n",
    "    - l_images - contain images\n",
    "    - l_lables - contain labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Array image importing / resizing / convert / reshape / labelling / shuffleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating initial array and resizing\n",
    "r_image_list = []\n",
    "img_count = 0\n",
    "path = \"/Users/hannansaleemi/Desktop/SDC/Jupyter Notebook Examples/cardataset/training_set/Right/\"\n",
    "for filename in glob.glob(path+'*.png'):\n",
    "    img_count += 1\n",
    "    image = misc.imread(path+'trainframe ('+str(img_count)+').png')\n",
    "    image_resized = resize(image, (18,22), mode='reflect')\n",
    "    r_image_list.append(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 22, 3)\n"
     ]
    }
   ],
   "source": [
    "#Just confiming the shape of the array\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished converting image # 0\n",
      "Finished converting image # 100\n",
      "Finished converting image # 200\n",
      "Finished converting image # 300\n",
      "Finished converting image # 400\n",
      "Finished converting image # 500\n",
      "Finished converting image # 600\n",
      "Finished converting image # 700\n",
      "Finished converting image # 800\n",
      "Finished converting image # 900\n",
      "Finished converting image # 1000\n",
      "Finished converting image # 1100\n",
      "Finished converting image # 1200\n",
      "Finished converting image # 1300\n",
      "Finished converting image # 1400\n",
      "Finished converting image # 1500\n",
      "Finished converting image # 1600\n",
      "Finished converting image # 1700\n",
      "Finished converting image # 1800\n",
      "Finished converting image # 1900\n",
      "Finished converting image # 2000\n",
      "Finished converting image # 2100\n",
      "Finished converting image # 2200\n",
      "Finished converting image # 2300\n",
      "Finished converting image # 2400\n",
      "Finished converting image # 2500\n",
      "Finished converting image # 2600\n",
      "Finished converting image # 2700\n",
      "Finished converting image # 2800\n",
      "Finished converting image # 2900\n"
     ]
    }
   ],
   "source": [
    "#Converting to greyscale\n",
    "r_grey = np.zeros((3000, image_resized.shape[0], image_resized.shape[1]))\n",
    "\n",
    "for image_num in range(len(r_image_list)):\n",
    "    for rownum in range(len(r_image_list[image_num])):\n",
    "        for colnum in range(len(r_image_list[image_num][rownum])):\n",
    "            r_grey[image_num][rownum][colnum] = weightedAverage(r_image_list[image_num][rownum][colnum])\n",
    "    #Output Logging\n",
    "    if image_num % 100 == 0:\n",
    "        print(\"Finished converting image #\", (image_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 18, 22)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the shape of the greyscale array\n",
    "r_grey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "r_images = r_grey.reshape(3000,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 396)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the new shape again\n",
    "r_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating Labels\n",
    "r_labels = np.zeros(shape=(3000,3))\n",
    "\n",
    "#Adding 3000 forward labels [1,0,0]\n",
    "for i in range(3000):\n",
    "    r_labels[i][2] = float(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just checking the labels\n",
    "r_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "r_images, r_labels = shuffle(r_images, r_labels, random_state = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42381863,  0.24559314,  0.33323431, ...,  0.32286176,\n",
       "         0.35372255,  0.37860392],\n",
       "       [ 0.53156373,  0.61470882,  0.64574902, ...,  0.83415686,\n",
       "         0.89350784,  0.86481569],\n",
       "       [ 0.24203922,  0.24657549,  0.21022059, ...,  0.54228235,\n",
       "         0.54340196,  0.52687745],\n",
       "       ..., \n",
       "       [ 0.28160098,  0.28735686,  0.29853725, ...,  0.21704412,\n",
       "         0.20153922,  0.18539902],\n",
       "       [ 0.29032451,  0.30502255,  0.33215882, ...,  0.56873725,\n",
       "         0.56399216,  0.84679706],\n",
       "       [ 0.66723333,  0.52322941,  0.17988235, ...,  0.56154608,\n",
       "         0.55193627,  0.51371471]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if they have shuffled\n",
    "r_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right Images Done:\n",
    "    - r_images - contain images\n",
    "    - r_lables - contain labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging all images and labels together into 2 seperate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_images_array = np.concatenate((f_images, l_images, r_images), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_labels_array = np.concatenate((f_labels, l_labels, r_labels), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle array to randomize order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20488431,  0.31913235,  0.40438627, ...,  0.93290392,\n",
       "         0.91115392,  0.90059118],\n",
       "       [ 0.16452059,  0.23098333,  0.24517451, ...,  0.45037843,\n",
       "         0.64341667,  0.86788725],\n",
       "       [ 0.52245294,  0.53974706,  0.56372451, ...,  0.88922059,\n",
       "         0.87743824,  0.86189804],\n",
       "       ..., \n",
       "       [ 0.28160098,  0.28735686,  0.29853725, ...,  0.21704412,\n",
       "         0.20153922,  0.18539902],\n",
       "       [ 0.29032451,  0.30502255,  0.33215882, ...,  0.56873725,\n",
       "         0.56399216,  0.84679706],\n",
       "       [ 0.66723333,  0.52322941,  0.17988235, ...,  0.56154608,\n",
       "         0.55193627,  0.51371471]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking states before\n",
    "all_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking states before\n",
    "all_labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the images\n",
    "all_images_array, all_labels_array = shuffle(all_images_array, all_labels_array, random_state = 9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62003333,  0.52430588,  0.68951275, ...,  0.52891176,\n",
       "         0.48937647,  0.66167353],\n",
       "       [ 0.31736471,  0.34797255,  0.32738529, ...,  0.62466667,\n",
       "         0.56809804,  0.55606569],\n",
       "       [ 0.04113922,  0.13658039,  0.16118039, ...,  0.47372941,\n",
       "         0.44008039,  0.38227353],\n",
       "       ..., \n",
       "       [ 0.61493627,  0.48115686,  0.42215098, ...,  0.66561863,\n",
       "         0.61916667,  0.57276275],\n",
       "       [ 0.58308529,  0.58470098,  0.55935392, ...,  0.59097059,\n",
       "         0.52669706,  0.56237059],\n",
       "       [ 0.25593529,  0.35657843,  0.32090294, ...,  0.83862549,\n",
       "         0.82238235,  0.80096667]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rechecking states\n",
    "all_images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rechecking states\n",
    "all_labels_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling Complete Data Set Complete\n",
    "     - all_images_array - contains image data\n",
    "     - all_labels_array - contains label data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving on to TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "    - Learning Rate - How quickly we adjust the cost function (tradeoff by setting it to very small vs setting is veyr big)\n",
    "    - Number of epochs - How many training cycles to go through - going through the same data over and over again\n",
    "    - Batch Size - sizes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learning_rate = 0.001\n",
    "learning_rate = 0.0001\n",
    "#training_epochs = 15\n",
    "training_epochs = 25\n",
    "batch_size = 640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Parameters: - Define what the NN or Multi-Layer Perceptron looks like:\n",
    "    - n_classes - ten types of inputs and outputs (0-9)\n",
    "    - n_samples - number of samples in the training data (55000) - can get the number by 'mnist.train.num_examples'\n",
    "    - n_input - what we expect the input to look like - 28x28 flattened vector so 784 inputs going in\n",
    "    - The model will have 2 hidden layers each with 256 nodes:\n",
    "        - n_hidden_1 - number of nuerons in hidden layer 1\n",
    "        - n_hidden_2 - number of neurons in hidden layer 2\n",
    "\n",
    "Why 256?\n",
    "    - Computers have a way of storing image information as 8 bit color storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "#n_samples = 9000\n",
    "n_samples = 9000\n",
    "n_input = 396\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan of Attack:\n",
    "    - First, Recieve input image data array\n",
    "    - Send it to the first hidden layer with weights multiplied and a bias\n",
    "    - Sent to next hidden layer with weights multiplied\n",
    "    - Then sent to output layer\n",
    "    - Calculate the error - Loss Function or Cost Function - How far off the desired result we are?\n",
    "    - Apply optimisation function to try and minimise the cost/error\n",
    "        - This is done by adjusting the weights accordingly across the whole network\n",
    "        - We will be using the adam optimiser\n",
    "            - This depends on the learning rate - the lower the rate, the higher the accuracy but really slow to reach target and after a certian amaount of time - there is no point to lower cost as it has already reached minimum\n",
    "            - The higher the rate, low accuracy, may never converge, may bouce around accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function for a multi-layer perceptron:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:\n",
    "RELU Activtaion function - good from images - rectifier function - either returns an x or 0 - whichever is greater\n",
    "Output layer Activation Function - Linear activation function - matrix multiplication\n",
    "2 hidden layers\n",
    "\n",
    "This function will take 3 arguments:\n",
    "    - x\n",
    "    - Weights\n",
    "    - biases\n",
    "\n",
    "So in the first layer:\n",
    "    - Mutiply all the x and weight values toghether (h1 contains weights for hidden layer 1) (NEEDS TO MATRIX MULTIPLY ALWAYS)\n",
    "    - The add all of the values of each x * weight and the bias summed together.\n",
    "    - Then we pass the value into the RELU Function\n",
    "        - What RELU does: f(x) = max(0,x)\n",
    "        \n",
    "The same as above is going on in the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights,biases):\n",
    "    '''\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: dict of bias values\n",
    "    '''\n",
    "    \n",
    "    ### First Hidden Layer with RELU Activation Function\n",
    "    # X * W + B\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    # RELU(X * W + B) -> f(x) = max(0,x)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    ### Last Output Layer\n",
    "    out_layer = tf.matmul(layer_1,weights['out']) + biases['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights\n",
    "\n",
    "We will now introduce tensorflow variables - This is a modifiable value, can even be modified by computation graph\n",
    "\n",
    "Generally, Model parameter are tensorflow variables\n",
    "\n",
    "REMEMBER: Weights are random to start off with, they will be fined tuned by the NN when calculating the cost/error\n",
    "\n",
    "tf.random_normal - outputs random values from a normal distribution - used to randomly initialise\n",
    "    - tf.random.normal([row, columns]) - creates a matrix of random values, with certain number of rows and columns\n",
    "\n",
    "WHY IS A MATRIX? HOW WILL THE VALUES GET ASSIGNED?\n",
    "    - So the input is 784 different pixel values and the next layer is made of 256 neurons. Each neuron in the input layer will\n",
    "      be connected to all neurons in the next layer and therefore there will be 784*256 weights, therefore assigning each \n",
    "      branch with a weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the weights dictionary\n",
    "'''\n",
    "    h1 - martix of randomly assigned values from a normal distribution. rows=784, columns=256\n",
    "    h2 - martix of randomly assigned values from a normal distribution. rows=256, columns=256\n",
    "    out - matric of randomly assigned values from a normal distribution. rows=256, columns=10\n",
    "'''\n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_1,n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAIT! What will the output look like:\n",
    "    - Well remeber above we set one-hot to true\n",
    "    - so 0 is represented as [1 0 0 0 0 0 0 0 0 0]\n",
    "         1 is represented as [0 1 0 0 0 0 0 0 0 0]\n",
    "         etc...\n",
    "    - So the output will also be an array like this \n",
    "      EG) it predicts it is 4 so output will be [0 0 0 0 1 0 0 0 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biases are are the same size as the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes])) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set two placeholders for x and y\n",
    "\n",
    "x - The same size as the input as the input is 784 array\n",
    "\n",
    "y - output - will be a 10 element array as there are only 10 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cost and optimiser functions\n",
    "\n",
    "We will use built in tensorflow functions for these parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Stage:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Session :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now actually train the model for the number of epochs we defines (15):\n",
    "\n",
    "More Info:\n",
    "    - So basically we get the total batch - 550\n",
    "    - Next we extract the x = the image data and the y = the label for those images correspondingly\n",
    "    - Do the training for that epoch and return the cost\n",
    "    - At the end of 15 loops/epochs - the model has been trained on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Cost 37.2280\n",
      "Epoch: 2 Cost nan\n",
      "Epoch: 3 Cost nan\n",
      "Epoch: 4 Cost nan\n",
      "Epoch: 5 Cost nan\n",
      "Epoch: 6 Cost nan\n",
      "Epoch: 7 Cost nan\n",
      "Epoch: 8 Cost nan\n",
      "Epoch: 9 Cost nan\n",
      "Epoch: 10 Cost nan\n",
      "Epoch: 11 Cost nan\n",
      "Epoch: 12 Cost nan\n",
      "Epoch: 13 Cost nan\n",
      "Epoch: 14 Cost nan\n",
      "Epoch: 15 Cost nan\n",
      "Epoch: 16 Cost nan\n",
      "Epoch: 17 Cost nan\n",
      "Epoch: 18 Cost nan\n",
      "Epoch: 19 Cost nan\n",
      "Epoch: 20 Cost nan\n",
      "Epoch: 21 Cost nan\n",
      "Epoch: 22 Cost nan\n",
      "Epoch: 23 Cost nan\n",
      "Epoch: 24 Cost nan\n",
      "Epoch: 25 Cost nan\n",
      "Model has completed 25 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "start_batch = 0\n",
    "end_batch = batch_size\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    #Cost\n",
    "    avg_cost = 0.0\n",
    "    \n",
    "    #Define total_batch as an integer\n",
    "    #9000/100 = 90\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        # Grab the next batch of data using the batch explaination i did above ^^^\n",
    "        #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        batch_x = all_images_array[start_batch:end_batch]\n",
    "        batch_y = all_labels_array[start_batch:end_batch]\n",
    "        \n",
    "        #Optimisation and Loss values - the '_' is a unwanted variable for tuple unpacking\n",
    "        #This will return a loss - which is assigned to 'c'\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "        start_batch += batch_size\n",
    "        end_batch += batch_size\n",
    "        \n",
    "    print(\"Epoch: {} Cost {:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parent directory of C:/Users/Hannan Saleemi/Documents/model.ckpt doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: C:/Users/Hannan Saleemi/Documents\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_3, Variable_3/Adam, Variable_3/Adam_1, beta1_power, beta2_power)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1473\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: C:/Users/Hannan Saleemi/Documents\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_3, Variable_3/Adam, Variable_3/Adam_1, beta1_power, beta2_power)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-52-18da33d742f9>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1140, in __init__\n    self.build()\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 686, in build\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 276, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 219, in save_op\n    tensors)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 768, in save_v2\n    tensors=tensors, name=name)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/hannansaleemi/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): C:/Users/Hannan Saleemi/Documents\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_3, Variable_3/Adam, Variable_3/Adam_1, beta1_power, beta2_power)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-c7b5025f000a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C:/Users/Hannan Saleemi/Documents/model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1488\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[1;32m   1489\u001b[0m                   save_path))\n\u001b[0;32m-> 1490\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parent directory of C:/Users/Hannan Saleemi/Documents/model.ckpt doesn't exist, can't save."
     ]
    }
   ],
   "source": [
    "save_path = saver.save(sess, \"C:/Users/Hannan Saleemi/Documents/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy.eval({x: all_images_array, y: all_labels_array})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SO WHAT HAS HAPPENED?\n",
    "\n",
    "    - So far i keep getting the GPU ran out of memory error (Resource Exhausted)\n",
    "        - To solve this either reduce batch size or reduce number of epochs - i had to do both\n",
    "    - The cost keeps bouncing around - maybe more layers needed / lower learning rat\n",
    "    - The model is evaluated on the training data - same data as trained on giving a 0.998667% accuracy\n",
    "    \n",
    "    - Maybe increase batch size and increase epochs\n",
    "    - or decarese batch size and increase epochs\n",
    "    - play around to avoid GPU Memory Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Apparently - i can reset GPU Memory anytime by calling this function:\n",
    "\n",
    "Best to reset GPU Memory after 8 epochs\n",
    "DOESN'T WORK - K is not defined!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_GPU_mem():\n",
    "    K.get_session()\n",
    "    cfg = K.tf.ConfigProto()\n",
    "    cfg.gpu_options.allow.growth = True\n",
    "    K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets test a prediction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_test = np.zeros(shape=(396))\n",
    "array_test = all_images_array[2400].reshape(1,396)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = sess.run(tf.argmax(pred, 1), feed_dict={x: array_test})\n",
    "if result == [2]:\n",
    "    print(\"Model has predicted: Right\")\n",
    "elif result == [1]:\n",
    "    print(\"Model has predicted: Left\")\n",
    "elif result == [0]:\n",
    "    print(\"Model has predicted: Forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw_img = all_images_array[2400].reshape(18,22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(draw_img, cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
